% math.hm
% mathematics!

\setoutputdir{math}
\addbreadcrumb{page_math}

\begin{page}{math.html}
  \label{page_math}
  \title{Mathematics}
  \modified{3 June 2012}

  This is an index of writing on mathematics.

  \begin{itemize}
  \item \ref{page_math_platonic}
  \item \ref{page_math_relations}
  %\item \ref{page_quotient_groups}
  \end{itemize}

  At some point, I hope to put up my lecture notes for a
  Splash\footnote{This is a program put on by ESP at MIT every year
    where hundreds of high-school (and younger) students come for a
    weekend to be taught about virtually any topic.} class I taught in
  2009 called ``The Joy of Eigenvalues'':
  \begin{quote}
    Linear recurrence relations, generating functions, graphs, oh my!
    We will explore the connection between these seemingly unrelated
    ideas by the numbers which are intrinsic to their
    structure. Applications include Google PageRank, vibrating
    systems, and population dynamics. We will start with the
    definition of an eigenvalue and continue from there (with many
    examples and $\lambda$'s).
  \end{quote}

  \section{Small problems}

  These are just some small problems with their solutions.

  \hline

  This one was given to me in my 5th grade math class.

  \textit{Suppose you have an array of lockers, labeled $1$, $2$, $3$,
    and so on, and they're all closed.  By ``toggling a locker,'' we
    mean opening it if its closed and closing it if it is open. You
    have a lot of time on your hands, so you decide to do the
    following.  First you toggle every locker, then you toggle lockers
    $2$, $4$, $6$, and so on (multiples of two).  Then you toggle
    lockers which are multiples of three, and then you keep doing this
    process of toggling the multiples of four, five, six, and so on.
    Which lockers are open by the end, if any? }

  You can try this experimentally, and with about 20 lockers you can
  see the pattern: the lockers which are open are those which are
  squares! (i.e., $1, 4, 9, 16, \ldots$).

  Why is this?  First, to determine whether a particular locker is
  open or not, all you need to know is whether the number of times it
  was toggled is even or odd.  Each locker is toggled once for each of
  its divisors, and divisors usually come in pairs (if $d$ is a
  divisor of $n$, then $n/d$ is a divisor of $n$, too).  But are $d$
  and $n/d$ distinct?  If $n$ is a square, then $d$ being its square
  root gives $d=n/d$.  If $n$ is not a square, then $d$ and $n/d$ are
  always different.  This means that a square has an odd number of
  divisors, and a non-square has an even number of divisors; hence,
  the squares are the ones with the open lockers!

\end{page}

\begin{page}{platonic.html}
  \label{page_math_platonic}
  \title{The five Platonic solids}
  \modified{3 June 2012}

  \begin{figure}[r]
    \label{fig_platonic}
    \includegraphics[alt=The five Platonic solids,width=300]{platonic_solids.jpg}
    \begin{center}
      \caption{Paper models of all five Platonic solids.}
    \end{center}
  \end{figure}

  I've been fascinated by polyhedra since I was really young.  My mom
  had this book called \link[\textit{Polyhedron Models for the
    Classroom}]{http://www.amazon.com/Polyhedron-Models-Classroom-Magnus-Wenninger/dp/0873530837}
  by Magnus Wenniger\footnote{According to a review of
    \textit{Polyhedron Models for the Classroom} on Amazon, the book
    is an excerpt from the book \link[\textit{Polyhedron
      Models}]{http://www.amazon.com/Polyhedron-Models-Magnus-J-Wenninger/dp/0521098599}
    by the same author.} which gave patterns for building models of
  all the regular and semiregular polyhedra as well as a short history
  of the pursuit to discover all of them.  I thought it was really
  cool, and I've made many models of the Platonic and Archimedean
  solids through the years.  Unlike polygons, there are only
  \textit{finitely many} Platonic solids.  Why is that?  In this page,
  I'll give a proof that there are at most five Platonic solids.

  The picture to the right shows a set of models of all five Platonic
  solids.  From left to right they are the tetrahedron, the
  dodecahedron, the cube (or hexahedron), the icosahedron, and the
  octahedron, and they are each named for their respective number of
  faces.  These forms have been known for thousands of years, and were
  named after Plato who, for better or for worse, said that each
  polyhedron corresponded to a different classical element (earth,
  air, fire, and water; he left the dodecahedron to the gods).  They
  really should have been named after Theaetetus, a contemporary of
  Plato, who first proved that there were exactly five regular convex
  polyhedra.  Or even Euclid, who completed the \textit{Elements} with
  constructions of each of the solids.

  I haven't been clear about what I mean by a regular polyhedron, so I
  give the following definition:

  \textbf{Definition.} A \emph{regular polyhedron} is a polyhedron
  whose faces are congruent regular polygons such that each vertex has
  the same number of incident faces.

  For a given regular convex polyhedron, we will let $n$ be the number
  of sides of each of its polygonal faces and $\mu$ be the number of
  faces around each vertex (where $\mu$ stands for
  \textit{monodromy}).  Out of our familiarity with regular polygons,
  we immediately know that $n\geq 3$.  I'll appeal to our geometric
  intuition to see that $\mu\geq 3$ as well (polyhedra must have some
  actual volume, which is analogous to the bound on $n$ for polygons).

  Let $v$, $e$, and $f$ be the numbers of vertices, edges, and faces,
  respectively of the polyhedron.  The quantity $\chi=v-e+f$ is known
  as the \textit{Euler characteristic}, and for convex polyhedra,
  $\chi$ is always $2$, a fact which has been proven so many times I'm
  not going to show it here.\footnote{ See \link[Nineteen Proofs of
    Euler's
    Theorem]{http://www.ics.uci.edu/~eppstein/junkyard/euler/}.

    One method of proof which isn't listed uses algebraic
    topology. First you show you can replace each face with triangles,
    and this does not change $\chi$.  This gives a simplicial complex
    which is homeomorphic to a $2$-sphere.  There is an exercise of
    Hatcher which says that alternating sums of the degrees of the
    homology groups of a space are constant up to homotopy
    equivalence.  For a $2$-sphere, this alternating sum is $1-0+1=2$.
    Since for simplicial complexes the alternating sum is the Euler
    characteristic, this shows that $\chi=2$.}

  We now make two observations.  The first is that $nf=2e$, which is
  obtained by noticing that each face in the polyhedron has $n$ edges
  around it, but each edge has two incident faces, so $nf$ double
  counts the number of edges.  The second is that $\mu v=2e$, which is
  obtained by noticing that each vertex has $\mu$ incident edges
  (separating each of the $\mu$ faces), and each edge has two incident
  vertices, so $\mu v$ also double counts the number of edges.  With
  these, we can write $v-e+f=2$ in terms of $n$, $\mu$, and $e$ as
  follows:
  \begin{equation*}
    \frac{1}{n} + \frac{1}{\mu} = \frac{1}{2} + \frac{1}{e}
  \end{equation*}
  I'm told that diophantine equations which are sums of reciprocals
  involve deep number theory, which is something I'd like to
  understand.\footnote{The page \link[Egyptian
    Fractions]{http://mathworld.wolfram.com/EgyptianFraction.html} on
    MathWorld deals with some equations of this form.  I think it also
    has something to do with Lie something-or-another.}
  
  Since $e$ is positive, this equation reduces to the following
  inequality:
  \begin{equation*}
    \frac{1}{n} + \frac{1}{\mu} > \frac{1}{2}
  \end{equation*}
  Let's now just do a case analysis to find all the solutions to this
  inequality.  We'll go through each possible value of $n$, starting
  with $3$ since $n\geq 3$.  For the following, recall that $\mu\geq
  3$.
  \begin{description}
  \item[\textbf{Case I.} $n=3$] In this case, $\mu<6$.  When $n=3$ and
    $\mu=3$, this is a tetrahedron, when $n=3$ and $\mu=4$, this is an
    octahedron, and when $n=3$ and $\mu=5$, this is an icosahedron.
  \item[\textbf{Case II.} $n=4$] In this case, $\mu<4$, so the only
    solution is $n=4$ and $\mu=3$, which is a hexahedron (cube).
  \item[\textbf{Case III.} $n=5$] In this case, $\mu<10/3$, so we have
    $n=5$ and $\mu=3$, which is the dodecahedron.
  \item[\textbf{Case IV.} $n\geq 6$] Then, since $\mu\geq 3$,
    \begin{equation*}
      \frac{1}{n} + \frac{1}{\mu} \leq \frac{1}{6} + \frac{1}{3} = \frac{1}{2},
    \end{equation*}
    so there is no solution.
  \end{description}

  We can verify that each of these solutions have corresponding
  integral values for $v$, $e$, and $f$, which we compute in the
  following table:
  \begin{center}
  \begin{tabular}{rr|rrr|l}
    $n$ & $\mu$ & $v$ & $e$ & $f$ & name \\
    \hline
    \hline
    3 & 3  & 4 & 6 & 4 & tetrahedron \\
    3 & 4  & 6 & 12 & 8 & octahedron \\
    3 & 5  & 12 & 30 & 20 & icosahedron \\
    4 & 3  & 8 & 12 & 6 & hexahedron (cube) \\
    5 & 3  & 20 & 30 & 12 & dodecahedron \\
  \end{tabular}
  \end{center}

  Therefore, we have shown that there cannot be more than five
  Platonic solids!

  Unfortunately, we have only proven that there are \textit{at most}
  five regular convex polyhedra, and no attempt has been made to show
  that each of these solutions correspond to an actual regular
  polyhedron, despite the suggestive images of paper models and my
  attempts identify the solutions with them.  I'll leave this as an
  exercise for the reader.  Or, you can read Book XIII of the
  \textit{Elements} (and probably most of the books leading up to it)
  to get constructions of each of them.
  
\end{page}

\begin{page}{quot_groups.html}
  \label{page_quotient_groups}
  \title{An exposition of quotient groups}
  \modified{2 December 2012}

  The purpose of this page is to show a different way of looking at
  quotient groups (and quotients in general).  A common presentation
  for quotient groups is to take the set of cosets and show that there
  is a natural group operation defined on them.  However, I feel that
  this muddles the intuition for the construction.

  Let $G$ be some arbitrary group, and let $H$ be some subgroup of
  $G$.  We can define a relation on $G$ as follows:
  \begin{equation*}
    x\equiv y\pmod{H}\text{\ if\ and\ only\ if\ }xy\inv\in H.
  \end{equation*}
  Note that the $\pmod{H}$ refers to the $\equiv$ symbol, not $y$.  We
  pronounce this as ``$x$ is equivalent to $y$, modulo $H$''.

  If we consider $G=\Z$ as an additive group, and let $H$ be the set
  of multiples of $5$, then this relation amounts to the standard
  definition for ``modulo 5'' on the integers (i.e., $x\equiv
  y\pmod{5}$ if and only if $x$ and $y$ are different by a multiple of
  $5$).

  The first minor result is that this relation is actually an
  equivalence relation (hence the suggestive pronunciation of the
  symbol).  Reflexivity follows from the definition of inverses,
  symmetry follows from the fact that the subgroup $H$ is closed under
  inverses, and transitivity follows from $H$ being closed under
  composition: if $x\equiv y$ and $y\equiv z\pmod{H}$, then both
  $xy\inv$ and $yz\inv$ are in $H$, so $(xy\inv)(yz\inv)$ is in $H$,
  too, and therefore $xz\inv$ is in $H$.

  The second minor result is that the composition law respects the
  equivalence, if and only if $H$ is a normal subgroup: that is, if
  $x_1\equiv x_2$ and $y_1\equiv y_2\pmod{H}$, then $x_1y_1\equiv
  x_2y_2\pmod{H}$.  Intuitively, this means we can ``replace likes
  with likes.''  Why does this work?  First, we know that $y_1y_2\inv$
  is in $H$.  Since $H$ is normal, this means that $x_1y_1y_2\inv
  x_1\inv$ is in $H$, too.  Since $x_1x_2\inv$ is in $H$, we can
  compose these to get $x_1y_1y_2\inv x_2\inv\in H$, which is the same
  as $x_1y_1(x_2 y_2)\inv$, and this proves that $x_1y_1\equiv
  x_2y_2\pmod{H}$.  Conversely, supposing that we can replace likes
  with likes, we will show that $H$ must therefore be normal.  Let
  $y\in H$ and $x\in G$.  Since $y\equiv 1\pmod{H}$ we have that
  $xyx\inv\equiv 1\pmod{H}$, by first left-multiplying and then
  right-multiplying by $x$ and $x\inv$, respectively.  Since this is
  equivalent to saying that $xyx\inv\in H$, and since both $x$ and $y$
  were arbitrary, this proves $H$ is a normal subgroup of $G$.

  The third minor result is that inverses still work as expected, but
  this is really easy to show: 

\end{page}

\begin{page}{relations.html}
  \label{page_math_relations}
  \title{The theory of relations}
  \modified{30 November 2012}

  I was reading \textit{Naive Set Theory} by Halmos, and he mentioned
  a reasonable definition for the composition of two relations, as
  well as the characterization of an equivalence relation using
  relation composition.  On this page, I want to explore relations in
  some more detail (this is presently a work in progress).

  We define a relation $R$ between two sets $X$ and $Y$ to be any
  subset of $X\times Y$, which we write as $R:X\leftrightarrows Y$ for
  short.  If $(x,y)\in R$, then we say that $x$ is related to $y$ by
  $R$.  We will write this symbolically as $y\r{R}x$.  While the
  standard notation for this is $x\r{R}y$, we differ here because it
  will aid in the notation for relation composition and for functions.

  We write $R(x)$ for the set of all $y$ such that $y\r{R}x$.  Or, if
  $U$ is a subset of $X$, then we write $R(U)$ to be the union of all
  the $R(x)$, where $x\in U$.  We define $(y)R$ and $(V)R$
  analogously.  If it so happens that $R(x)$ or $(y)R$ are singleton
  sets, then we pretend that $R(x)$ or $(y)R$ are the element of their
  corresponding singleton set.  Two special sets are the
  \textit{image} of a relation, $R(X)$, and the \textit{co-image} (or
  \textit{domain}) of a relation, $(Y)R$.

  The inverse of a relation $R:X\leftrightarrows Y$ is a relation
  $R\inv:Y\leftrightarrows X$ defined by $x\r{R\inv}y$ whenever
  $y\r{R}x$.  Generally, something is \textit{co-} for some relation
  if the non-\textit{co-} version applies to its inverse (i.e., ``the
  arrows are reversed'').

  There are a few important properties for a relation:
  \begin{itemize}
  \item $R$ is a \textit{surjection} if for any $y\in Y$, there exists
    an $x\in X$ such that $y\r{R}x$.  We can also define surjectivity
    by the condition $R(X)=Y$.
  \item $R$ is a \textit{co-surjection} if $R\inv$ is a surjection.
    Similarly, we can also say that $R$ is co-surjective if $(Y)R=X$.
  \item $R$ is an \textit{injection} if whenever $x_1,x_2\in X$ and
    $y\in Y$ are such that $y\r{R}x_1$ and $y\r{R}x_2$, then
    $x_1=x_2$.  We could just have well said that $R$ is
    \textit{one-to-many}.  An example of such a relation is ``is the
    biological mother of'' if $X$ and $Y$ are both the set of all
    people.
  \item $R$ is a \textit{co-injection} if $R\inv$ is an injection.
    This property is the same as saying that $R$ is
    \textit{many-to-one}.  An example of this is the relation ``lives
    in'' for $X$ being the set of all people and $Y$ being the set of
    all houses.  Note that this relation isn't necessarily a
    co-surjection since not everyone needs to live in a house.
  \end{itemize}

  A relation which is both an injection and an co-injection can also
  be called \textit{one-to-one}.  An example of such a relation is
  ``is the right foot of'' where $X$ is the set of feet and $Y$ is the
  set of people.

  A \textit{function} $f:X\to Y$ is a relation which is a
  co-surjection and a co-injection.  This means that for every $x\in
  X$, there is exactly one $y\in Y$ such that $y\r{f}x$.  We refer to
  this $y$ using the notation $f(x)$.  A \textit{co-function} is a
  relation whose inverse is a function.  Note that this means a
  co-function is a surjection and an injection.  Hence, a
  \textit{bijection} is a relation which is both a function and a
  co-function.

  We define the composition of two relations $R:X\leftrightarrows Y$
  and $S:Y\leftrightarrows Z$ to be a relation $SR:X\leftrightarrows
  Z$ defined by $z\r{SR}x$ whenever $z\r{S}y$ and $y\r{R}x$ for some
  $y\in Y$.  In general, if $R$ and $S$ are relations which both
  satisfy the same one of the four properties, then $SR$ has that
  property, too.  In particular, if $f:X\to Y$ and $g:Y\to Z$ are
  functions, then we see that $gf$ is also a function: $gf$ is a
  co-surjection since, for any $x\in X$, there is a $y\in Y$ such that
  $y\r{f}x$, and there is a $z\in Z$ such that $z\r{g}y$, hence
  $z\r{gf}x$; and $gf$ is a co-injection since, if $z_1,z_2\in Z$ and
  $x\in X$ are such that $z_1\r{gf}x$ and $z_2\r{gf}x$, there are
  $y_1,y_2\in Y$ such that $y_1\r{f}x$ and $y_2\r{f}x$, so $y_1=y_2$
  by co-injectivity of $f$, and hence $z_1=z_2$ by co-injectivity of
  $g$.

  What is the inverse of the composition of relations?  Suppose we
  want to check if $x\r{(SR)\inv} z$, which is equivalent to
  $z\r{SR}x$, which is equivalent to some $y\in Y$ existing such that
  $z\r{S}y$ and $y\r{R}x$, which is equivalent to $x\r{R\inv} y$ and
  $y\r{S\inv} x$ for some $y\in Y$, and this is equivalent to
  $x\r{R\inv S\inv} y$.  Therefore, $(SR)\inv=R\inv S\inv$.

  One can see that composition of relations is associative, as one
  would expect (at least one would expect for functions, at least).

  Define $I_A:A\leftrightarrows A$ to be the relation consisting only
  of $(a,a)$ for all $a\in A$.  Some common properties for a relation
  $R:X\to X$ can be described as follows:
  \begin{itemize}
  \item A relation is \textit{reflexive} if $I_X\subset R$.
  \item A relation is \textit{symmetric} if $R\subset R\inv$ (or,
    equivalently, if $R\inv\subset R$).
  \item A relation is \textit{transitive} if $RR\subset R$.
  \end{itemize}

  An \textit{equivalence relation} on $X$ is a relation
  $R:X\leftrightarrows X$ which satisfies all three of these
  properties (which I suppose can be succinctly written as $I_X\subset
  RR\subset R\subset R\inv$, using the fact that $R\subset RR$ by the
  reflexive property).

  There is a canonical equivalence relation on $X$ for a function
  $f:X\to Y$ defined by $f\inv f$, which says that two elements $x_1$
  and $x_2$ in $X$ are related if and only if $f(x_1)=f(x_2)$.  The
  proof for this is straight-forward.  First, for an arbitrary $x\in
  X$, there is a $y\in Y$ such that $y\r{f}x$, so since $x\r{f\inv}
  x$, we have reflexivity: $x\r{f\inv f}x$.  Second suppose that $x_2
  \r{f\inv f} x_1$.  Then there is a $y\in Y$ such that $y \r{f} x_2$
  and $y \r{f} x_1$, so $x_1\r{f}x_2$, hence symmetry.  Third, suppose
  that $x_3 \r{f\inv f} x_2$ and $x_2 \r{f\inv f} x_1$.  Then there
  are $y$ and $z$ such that $y \r{f} x_3$, $y \r{f} x_2$, $z \r{f}
  x_2$, and $z \r{f} x_1$.  By co-injectivity, $y=z=f(x_2)$, and so
  $x_3 \r{f\inv f} x_1$, hence transitivity.

  As an aside, since an equivalence relation is equivalent to a
  partition of a set, we have a first isomorphism theorem for sets by
  this construction: the set of partitions of $X$ induced by $f\inv f$
  is in bijective correspondence to the image of $f$.

  Suppose $R:X\leftrightarrows X$ is a relation on a set $X$.  What is
  the smallest equivalence relation $E$ on $X$ which contains $R$?  We
  know that $I_X$ must be in $E$ for reflexivity, and we know that
  $R\inv$ must be in $E$, too. Let $S=R\cup R\inv$, which is the
  symmetrified $R$.  Let $E$ be the union of $I_X$, $S$, $SS$, $SSS$,
  $SSSS$, and so on (this could be called the \textit{transitive
    closure} of $S$ if it didn't have the $I_X$ term).  For
  convenience, let $S^n$ represent $S$ composed with itself $n$ times,
  with $S^0=I_X$.  Since each $S^n$ is symmetric, $E$ is symmetric as
  well.  Furthermore, suppose $y\r{E}x$ and $z\r{E}y$.  Then,
  $y\r{S^n}x$ and $z\r{S^m}y$ for some $n,m$.  Then, $z\r{S^{n+m}}y$,
  and so $E$ is transitive.  %Actually, we could have just let $E=H\inv
%  H$, where $H=I_X\cup R$.  Note the similarity between the formulas
%   \begin{equation*}
%     \frac{1}{1+x} = 1 + x + x^2 +x^3+\ldots
%   \end{equation*}
%   and
%   \begin{equation*}
%     (I_X\cup R)\inv = I_x\cup R\cup R^2\cup R^3\cup\ldots.
%   \end{equation*}
%   There are nice algebraic properties between unions and compositions
%   of relations.  For instance, if $T,U,V:X\leftrightarrows Y$ are
%   relations, $(T\cup U)V=TV\cup UV$.  I'm sure more can be said about
%   this aspect of relations, but I'll leave that as an exercise for the
%   reader until I get around to it.
  This shows $E$ is an equivalence relation containing $R$, but is it
  the smallest such?  Since any equivalence relation which contains
  $R$ must contain $I_X$, $S$, $SS$, and so on, and $E$ contains no
  more than this, it follows that $E$ is smallest.

  It turns out we can define (co-)surjectivity and (co-)injectivity
  using composition properties, too:
  \begin{itemize}
  \item A relation is surjective if and only if $I_Y\subset RR\inv$.
  \item A relation is co-surjective if and only if $I_X\subset R\inv R$.
  \item A relation is injective if and only if $R\inv R\subset I_X$.
  \item A relation is co-injective if and only if $RR\inv\subset I_Y$.
  \end{itemize}

  So, if $R\inv R=I_X$, then $R$ is co-surjective and injective, and
  if $RR\inv=I_Y$, then $R$ is surjective and co-injective.  So, if
  $S:X\leftrightarrows X$, and $S\inv S=SS\inv=I_X$, then $S$ is a
  bijection (and, as a consequence, a group of relations with relation
  composition as the binary operation is actually a group of
  bijections).

  We see that some of the proofs for $f\inv f$ being an equivalence
  relation can be done more algebraically: first, $(f\inv f)\inv=f\inv
  f$, so it is symmetric; second, $(f\inv f)(f\inv
  f)=f\inv(ff\inv)f=f\inv I_Af$ since $f$ is co-injective, where
  $A\subset Y$ is the image of $f$, and $f\inv I_Af=f\inv f$, hence
  $f\inv f$ is transitive.

  There are nice algebraic properties for unions and intersections.
  Let $R:X\leftrightarrows Y$ and $U,V\subset X$.  Then $R(U\cup
  V)=R(U)\cup R(V)$, by definition.  We also have that $R(U\cap
  V)\subset R(U)\cap R(V)$, since if $y\r{R}x$ for some $x\in U\cap
  V$, then because $x$ is in both $U$ and $V$, $y$ is in $R(U)\cap
  R(V)$.  If, in addition, $R$ is surjective, then it is an equality:
  $R(U\cap V)=R(U)\cap R(V)$.  The inverse of a function is a
  surjective relation, so this is why unions and intersections work so
  nicely with them.
  
\end{page}
